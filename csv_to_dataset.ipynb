{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BwkS2rMIUtS0",
        "outputId": "54c34ac2-9f74-4c0c-f5e4-c4764c1f9d67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a73c3848-ef84-4f15-91dc-2b63839f3f5b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a73c3848-ef84-4f15-91dc-2b63839f3f5b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving A_Christmas_Carol.xlsx to A_Christmas_Carol.xlsx\n",
            "Saving Collision_of_Worlds_1.xlsx to Collision_of_Worlds_1.xlsx\n",
            "Saving Collision_of_Worlds_2.xlsx to Collision_of_Worlds_2.xlsx\n",
            "Saving Collision_of_Worlds_3.xlsx to Collision_of_Worlds_3.xlsx\n",
            "Saving Collision_of_Worlds_4.xlsx to Collision_of_Worlds_4.xlsx\n",
            "Saving Collision_of_Worlds_5.xlsx to Collision_of_Worlds_5.xlsx\n",
            "Saving Falling_Sentences.xlsx to Falling_Sentences.xlsx\n",
            "Saving Frankenstein.xlsx to Frankenstein.xlsx\n",
            "Saving In_Amundsen’s_Tent.xlsx to In_Amundsen’s_Tent.xlsx\n",
            "Saving Leiningen_Versus_the_Ants.xlsx to Leiningen_Versus_the_Ants.xlsx\n",
            "Saving Observer_1-A_Warm_Home.xlsx to Observer_1-A_Warm_Home.xlsx\n",
            "Saving Observer_2-Charity.xlsx to Observer_2-Charity.xlsx\n",
            "Saving Observer_3-One_of_Us.xlsx to Observer_3-One_of_Us.xlsx\n",
            "Saving Observer_4-Legends.xlsx to Observer_4-Legends.xlsx\n",
            "Saving Prince_and_the_Pauper.xlsx to Prince_and_the_Pauper.xlsx\n",
            "Saving The_Demon_King.xlsx to The_Demon_King.xlsx\n",
            "Saving The_Exiled_Queen.xlsx to The_Exiled_Queen.xlsx\n",
            "Saving The_Human_Chair.xlsx to The_Human_Chair.xlsx\n",
            "Saving The_Landlady.xlsx to The_Landlady.xlsx\n",
            "Saving The_Legend_of_Sleepy_Hollow.xlsx to The_Legend_of_Sleepy_Hollow.xlsx\n",
            "Saving The_Man_In_The_Well.xlsx to The_Man_In_The_Well.xlsx\n",
            "Saving The_Monkey_s_Paw.xlsx to The_Monkey_s_Paw.xlsx\n",
            "Saving The_Most_Dangerous_Game.xlsx to The_Most_Dangerous_Game.xlsx\n",
            "Saving The_Necklace.xlsx to The_Necklace.xlsx\n",
            "Saving The_Night_Rider.xlsx to The_Night_Rider.xlsx\n",
            "Saving The_Night_Wire.xlsx to The_Night_Wire.xlsx\n",
            "Saving The_Old_Man_And_The_Sea.xlsx to The_Old_Man_And_The_Sea.xlsx\n",
            "Saving The_Ransom_of_Red_Chief.xlsx to The_Ransom_of_Red_Chief.xlsx\n",
            "Saving The_Sun_Also_Rises.xlsx to The_Sun_Also_Rises.xlsx\n",
            "Saving The_Terrible_Old_Man.xlsx to The_Terrible_Old_Man.xlsx\n",
            "Saving There_Will_Come_Soft_Rains.xlsx to There_Will_Come_Soft_Rains.xlsx\n",
            "Saving To_Build_A_Fire.xlsx to To_Build_A_Fire.xlsx\n",
            "Saving Uncle_Toms_Cabin.xlsx to Uncle_Toms_Cabin.xlsx\n",
            "Saving Winnie_The_Pooh.xlsx to Winnie_The_Pooh.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stories = {}\n",
        "dataset = []\n",
        "NEIGHBORHOOD_RADIUS = 4\n",
        "\n",
        "for file_name, file_data in uploaded.items():\n",
        "    try:\n",
        "        df = pd.read_excel(file_data, header=None)\n",
        "\n",
        "        # Check for annotation\n",
        "        if 1 not in df[0].values:\n",
        "          print(f\"No scene transition found in {file_name}, skipping...\")\n",
        "          continue\n",
        "\n",
        "        # Find the index of the first '1' in the first column\n",
        "        first_scene_transition_index = df[df[0] == 1].index[0]\n",
        "\n",
        "        # fill any missed entries with 0\n",
        "        df[0] = df[0].fillna(0)\n",
        "\n",
        "         # Remove rows where the sentence is empty\n",
        "        df = df.dropna(subset=[1])\n",
        "        df = df[df[1] != 0]\n",
        "        df = df[df[1] != '0']\n",
        "\n",
        "        # # Slice the DataFrame to keep only the rows from the first '1' onwards\n",
        "        df = df.iloc[first_scene_transition_index:].reset_index(drop=True)\n",
        "\n",
        "        stories[file_name] = df\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_name}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "e9Dds3HLU4vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "474e3321-d791-4f9b-97bb-3a7dbe81b145"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No scene transition found in Prince_and_the_Pauper.xlsx, skipping...\n",
            "No scene transition found in The_Legend_of_Sleepy_Hollow.xlsx, skipping...\n",
            "No scene transition found in There_Will_Come_Soft_Rains.xlsx, skipping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence_neighborhoods(df, radius=NEIGHBORHOOD_RADIUS):\n",
        "\n",
        "    \"\"\"\n",
        "    Generates sentence neighborhoods centered around transition points in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pandas.DataFrame) : Assumption is that the first row is a scene transition\n",
        "    - radius : Number of sentences around the transition to include (before offsets)\n",
        "\n",
        "    Returns:\n",
        "    - list of pandas.DataFrame: A list containing the neighborhoods as DataFrames with one entry. A flattening of the neighborhood\n",
        "\n",
        "    Notes:\n",
        "    - For adjacent transitions (or story beginnings) only one neighborhood in the direction opposite to the conflict is returned\n",
        "    - Only neighborhoods that contain at least one sentence before or after the transition (not including\n",
        "      the transition itself) are included in the output.\n",
        "    \"\"\"\n",
        "\n",
        "    neighborhoods = []\n",
        "    length = ( radius * 2 ) + 1\n",
        "\n",
        "    transition_indices = df.index[df[0] == 1].tolist()  # Scene transition indices\n",
        "\n",
        "    for idx in transition_indices:\n",
        "\n",
        "      # These are the number of rows I can crawl up and down without hitting another transition\n",
        "      max_prev_distance = get_distance_to_prev_transition(df, idx) - 1\n",
        "      max_next_distance = get_distance_to_next_transition(df, idx) - 1\n",
        "\n",
        "      # Indices of next and previous transitions\n",
        "      prev_transition_index = idx - get_distance_to_prev_transition(df, idx)\n",
        "      next_transition_index = idx + get_distance_to_next_transition(df, idx)\n",
        "\n",
        "      # Define the start and end indices of the neighborhood\n",
        "      start_idx = idx - min(radius, max_prev_distance, max_next_distance)\n",
        "      end_idx = idx + min(radius, max_prev_distance, max_next_distance)\n",
        "\n",
        "      # Offset is where we define where we place the transition in the quartile, currently it is centered, rounding down\n",
        "      neighborhood_size = end_idx - start_idx\n",
        "      offset = neighborhood_size // 3\n",
        "\n",
        "      # In cases with adjacent transitions this bonus allows us to grab at least one neighborhood where our transition is on the edge and we go out one radius length away from the other transition\n",
        "      if (max_next_distance == 0):\n",
        "        backward_bonus = radius\n",
        "      else :\n",
        "        backward_bonus = 0\n",
        "      if (max_prev_distance == 0):\n",
        "        forward_bonus = radius\n",
        "      else :\n",
        "        forward_bonus = 0\n",
        "      if (max_next_distance == 0 and max_prev_distance == 0):\n",
        "        continue\n",
        "\n",
        "      # Truncate this neighborhood if our desired offset captures another transition\n",
        "      if (prev_transition_index >= (start_idx - offset)):\n",
        "        last_third_start = prev_transition_index + 1\n",
        "      else :\n",
        "        last_third_start = start_idx - offset\n",
        "\n",
        "      if (next_transition_index <= (end_idx + offset + 1)):\n",
        "        first_third_end = next_transition_index - 1\n",
        "      else :\n",
        "        first_third_end = end_idx + offset\n",
        "\n",
        "      # Capture neighborhoods\n",
        "      first_third = df.iloc[start_idx + offset : first_third_end + 1 + forward_bonus]\n",
        "      mid_third = df.iloc[start_idx : end_idx + 1]\n",
        "      last_third = df.iloc[last_third_start - backward_bonus: end_idx - offset + 1]\n",
        "\n",
        "      # Make sure the transition isn't alone, then flatten\n",
        "      if (first_third[0] == 0).any():\n",
        "        neighborhoods.append(flatten(pad_neighborhood(first_third, length)))\n",
        "\n",
        "      if (mid_third[0] == 0).any():\n",
        "        neighborhoods.append(flatten(pad_neighborhood(mid_third, length)))\n",
        "\n",
        "      if (last_third[0] == 0).any():\n",
        "        neighborhoods.append(flatten(pad_neighborhood(last_third, length)))\n",
        "\n",
        "    return neighborhoods\n",
        "\n",
        "\n",
        "def get_distance_to_prev_transition(df, index) :\n",
        "  if index == 0:      # Start of story\n",
        "        return 1\n",
        "  for i in range(index - 1, -1, -1):\n",
        "      if df.iloc[i, 0] == 1:\n",
        "          return index - i\n",
        "  return None\n",
        "\n",
        "def get_distance_to_next_transition(df, index) :\n",
        "    for i in range(index + 1, len(df)):\n",
        "        if df.iloc[i, 0] == 1:\n",
        "            return i - index\n",
        "    return len(df) - index # Count the end of the story as the next scene transition\n",
        "\n",
        "def pad_neighborhood(neighborhood, length):\n",
        "    rows_to_add = length - len(neighborhood)\n",
        "\n",
        "    # If the DataFrame needs padding\n",
        "    if rows_to_add > 0:\n",
        "        padding = pd.DataFrame(np.nan, index=range(rows_to_add), columns=neighborhood.columns)\n",
        "        neighborhood = pd.concat([neighborhood, padding], ignore_index=True)\n",
        "\n",
        "    return neighborhood\n",
        "\n",
        "def flatten(neighborhood):\n",
        "    filtered_sentences = neighborhood[1].dropna().tolist()\n",
        "\n",
        "    # Join the sentences into a single string with spaces\n",
        "    concatenated_sentences = ' '.join(filtered_sentences)\n",
        "\n",
        "    # Create and return DataFrame with a single entry\n",
        "    return pd.DataFrame([concatenated_sentences])"
      ],
      "metadata": {
        "id": "SlSPP_mjakIv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_neighborhoods = []\n",
        "\n",
        "for file_name, df in stories.items():\n",
        "    print(f\"Processing {file_name}...\")\n",
        "    try:\n",
        "        neighborhoods = generate_sentence_neighborhoods(df, NEIGHBORHOOD_RADIUS)\n",
        "\n",
        "        all_neighborhoods.extend(neighborhoods)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "# Concatenate all neighborhood DataFrames into a single DataFrame\n",
        "if all_neighborhoods:\n",
        "    neighborhoods_df = pd.concat(all_neighborhoods, ignore_index=True)\n",
        "\n",
        "    neighborhoods_df.to_csv('all_neighborhoods.csv', index=False)\n",
        "    print(\"All neighborhoods have been exported to 'all_neighborhoods.csv'.\")\n",
        "else:\n",
        "    print(\"No neighborhoods to export.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOO1mgNMZ4oz",
        "outputId": "65714612-2647-4bda-c6c3-03660848b911"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing A_Christmas_Carol.xlsx...\n",
            "Processing Collision_of_Worlds_1.xlsx...\n",
            "Processing Collision_of_Worlds_2.xlsx...\n",
            "Processing Collision_of_Worlds_3.xlsx...\n",
            "Processing Collision_of_Worlds_4.xlsx...\n",
            "Processing Collision_of_Worlds_5.xlsx...\n",
            "Processing Falling_Sentences.xlsx...\n",
            "Processing Frankenstein.xlsx...\n",
            "Processing In_Amundsen’s_Tent.xlsx...\n",
            "Processing Leiningen_Versus_the_Ants.xlsx...\n",
            "Processing Observer_1-A_Warm_Home.xlsx...\n",
            "Processing Observer_2-Charity.xlsx...\n",
            "Processing Observer_3-One_of_Us.xlsx...\n",
            "Processing Observer_4-Legends.xlsx...\n",
            "Processing The_Demon_King.xlsx...\n",
            "Processing The_Exiled_Queen.xlsx...\n",
            "Processing The_Human_Chair.xlsx...\n",
            "Processing The_Landlady.xlsx...\n",
            "Processing The_Man_In_The_Well.xlsx...\n",
            "Processing The_Monkey_s_Paw.xlsx...\n",
            "Processing The_Most_Dangerous_Game.xlsx...\n",
            "Processing The_Necklace.xlsx...\n",
            "Processing The_Night_Rider.xlsx...\n",
            "Processing The_Night_Wire.xlsx...\n",
            "Processing The_Old_Man_And_The_Sea.xlsx...\n",
            "Processing The_Ransom_of_Red_Chief.xlsx...\n",
            "Processing The_Sun_Also_Rises.xlsx...\n",
            "Processing The_Terrible_Old_Man.xlsx...\n",
            "Processing To_Build_A_Fire.xlsx...\n",
            "Processing Uncle_Toms_Cabin.xlsx...\n",
            "Processing Winnie_The_Pooh.xlsx...\n",
            "All neighborhoods have been exported to 'all_neighborhoods.csv'.\n"
          ]
        }
      ]
    }
  ]
}